{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "AuW-xg_bTsaF",
      "metadata": {
        "id": "AuW-xg_bTsaF"
      },
      "source": [
        "# Hands-on Lab: Cats vs Dogs Image Classifiers\n",
        "\n",
        "Welcome to the hands-on lab! You will be using the famous `Cats vs Dogs` dataset to train a model that can classify images of dogs from images of cats. For this, you will use Convolutional Neural Network in Tensorflow and leverage Keras image preprocessing utilities.\n",
        "\n",
        "You will also create some helper functions to move the images around the filesystem so if you are not familiar with the `os` module be sure to take a look a the [docs](https://docs.python.org/3/library/os.html).\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dn-6c02VmqiN",
      "metadata": {
        "id": "dn-6c02VmqiN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split \n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bLTQd84RUs1j",
      "metadata": {
        "id": "bLTQd84RUs1j"
      },
      "source": [
        "Download the dataset from its original source by running the cell below. \n",
        "\n",
        "Note that the `zip` file that contains the images is unzipped under the `/tmp` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3sd9dQWa23aj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sd9dQWa23aj",
        "lines_to_next_cell": 2,
        "outputId": "5cae5a66-75c4-4aa0-b938-d1c5e0a3d626",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
        "\n",
        "# Note: This is a very large dataset and will take some time to download\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e_HsUV9WVJHL",
      "metadata": {
        "id": "e_HsUV9WVJHL"
      },
      "source": [
        "Now the images are stored within the `/tmp/PetImages` directory. There is a subdirectory for each class, so one for dogs and one for cats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DM851ZmN28J3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM851ZmN28J3",
        "outputId": "136ecb45-41dc-4e81-c0dd-752f86e71cfa",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# source_path = '/tmp/PetImages'\n",
        "source_path = '/Users/mdaniyalk/Documents/github/learn/image-processing-gdsc-ugm/tmp/PetImages'\n",
        "\n",
        "source_path_dogs = os.path.join(source_path, 'Dog')\n",
        "source_path_cats = os.path.join(source_path, 'Cat')\n",
        "\n",
        "# Deletes all non-image files (there are two .db files bundled into the dataset)\n",
        "!find /tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
        "\n",
        "# Deletes corrupt images files\n",
        "class_names = ['Cat', 'Dog']\n",
        "for _class in class_names:\n",
        "  folder_path = os.path.join(source_path, _class)\n",
        "  for img_file in os.listdir(folder_path):\n",
        "    path = os.path.join(folder_path, img_file)\n",
        "    try:\n",
        "      image=tf.keras.preprocessing.image.load_img(path)\n",
        "    except:\n",
        "      print(f'Removing {img_file} in {_class}')\n",
        "      os.remove(path)\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\n",
        "print(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a2c8b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def preview_sample(SOURCE_DIR, NUM_OF_IMGS):\n",
        "  \"\"\"\n",
        "  Preview sample images from directories\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    NUM_OF_IMGS (int): number sample of images to preview\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  for i in range(NUM_OF_IMGS):\n",
        "    img_class = random.choice(['Cat', 'Dog'])\n",
        "    folder_path = os.path.join(SOURCE_DIR, img_class)\n",
        "    img_path = os.listdir(folder_path)\n",
        "    img = image.imread(os.path.join(folder_path, random.choice(img_path)))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "87dc7f7a",
      "metadata": {},
      "source": [
        "Displaying random sample images from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6088a3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "preview_sample(source_path, 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ce0f7350",
      "metadata": {},
      "source": [
        "Read Images and it's labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3d2701",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(SOURCE_DIR, CLASS_NAME, TARGET_SIZE):\n",
        "  \"\"\"\n",
        "  Load images and labels from directories\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    CLASS_NAME (array_like): Array of class names\n",
        "    TARGET_SIZE (array_like): Dimension of the images\n",
        "    \n",
        "  Returns:\n",
        "    array_like: Images data\n",
        "    array_like: Images label\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = []\n",
        "  label = []\n",
        "\n",
        "  for _class in CLASS_NAME:\n",
        "    tmp_dataset = []\n",
        "    folder_path = os.path.join(SOURCE_DIR, _class)\n",
        "    for img_file in os.listdir(folder_path):\n",
        "      path = os.path.join(folder_path, img_file)\n",
        "      try:\n",
        "        image=tf.keras.preprocessing.image.load_img(path, color_mode='rgb', \n",
        "              target_size=TARGET_SIZE)\n",
        "      except:\n",
        "        print(f'File {img_file} in {_class} is corrupted')\n",
        "      else:\n",
        "        image=tf.keras.preprocessing.image.load_img(path, color_mode='rgb', \n",
        "            target_size=TARGET_SIZE)\n",
        "        image=np.array(image)\n",
        "        tmp_dataset.append(image)\n",
        "        del image\n",
        "        label.append(_class)\n",
        "    dataset.append(np.asarray(tmp_dataset))\n",
        "    del tmp_dataset\n",
        "  dataset = np.concatenate(dataset, axis=0)\n",
        "  \n",
        "  # Label converter\n",
        "  labels = []\n",
        "  for _label in label:\n",
        "    labels.append(CLASS_NAME.index(_label))\n",
        "    \n",
        "  # One hot encoder for multiple classes\n",
        "  if len(CLASS_NAME) > 2:\n",
        "    labels = tf.keras.utils.to_categorical(labels).astype(int)\n",
        "  del label\n",
        "\n",
        "  return dataset, np.asarray(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d27fcf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_name = ['Cat', 'Dog']\n",
        "dataset, labels = load_dataset(source_path, class_name, (150,150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fdf5af",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking dataset and labels shape\n",
        "print(dataset.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df37a24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train test split\n",
        "train_data, test_data, label_train, label_test = train_test_split(dataset, labels, train_size=0.9, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d659f6ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking train, test, and it's label shape\n",
        "print(train_data.shape)\n",
        "print(label_train.shape)\n",
        "print(test_data.shape)\n",
        "print(label_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "633f088f",
      "metadata": {},
      "source": [
        "Defining the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oDPK8tUB_O9e",
      "metadata": {
        "cellView": "code",
        "id": "oDPK8tUB_O9e",
        "lines_to_next_cell": 2,
        "tags": []
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Lambda(lambda x: x/255, input_shape=(150, 150, 3)), # Normalize the input images\n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # tf.keras.layers.BatchNormalization(), # Uncomment to use BatchNormalization\n",
        "      tf.keras.layers.GlobalAveragePooling2D(),\n",
        "      # tf.keras.layers.Flatten(), # If you use GlobalAveragePooling, comment this line\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.8), # Uncomment to use dropout\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5qE1G6JB4fMn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qE1G6JB4fMn",
        "outputId": "a545b00a-b997-4276-f364-38165ab7a80a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get the untrained model\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5228475b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e96c80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_data, label_train,batch_size=64, validation_split=0.1, epochs=5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "VGsaDMc-GMd4",
      "metadata": {
        "id": "VGsaDMc-GMd4"
      },
      "source": [
        "Once training has finished, you can run the following cell to check the training and validation accuracy achieved at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MWZrJN4-65RC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "MWZrJN4-65RC",
        "outputId": "86329302-9faa-4fb2-f56b-d536de4893e1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, 'r', label='acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='val_acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, 'r', label='loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='val_loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4673048e",
      "metadata": {},
      "source": [
        "Test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b377bab1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_prediction(model, data, label, CLASS_NAME):\n",
        "  \"\"\"\n",
        "  Preview sample images from directories\n",
        "  \n",
        "  Args:\n",
        "    model: trained model\n",
        "    data (array-like): data to predict\n",
        "    label (array-like) : true label of data\n",
        "    CLASS_NAME (array_like): Array of class names\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  idx = randint(0, label.shape[0]-1)\n",
        "  x = np.expand_dims(data[idx], axis=0)\n",
        "  y_pred = model.predict(x)\n",
        "  y_pred = round(y_pred.flatten()[0])\n",
        "  plt.imshow(data[idx])\n",
        "  plt.xlabel(f'Predicted class: {CLASS_NAME[y_pred]}\\nActual class: {CLASS_NAME[label[idx]]}')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae220ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "make_prediction(model, test_data, label_test, class_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "406b3767",
      "metadata": {},
      "source": [
        "Inspect our features extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74523b24",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_layer(model, data):\n",
        "  \"\"\"\n",
        "  Feature extractor inspection and visualizer\n",
        "  \n",
        "  Args:\n",
        "    model: trained model\n",
        "    data (array-like): data to predict\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"  \n",
        "  successive_outputs = [layer.output for layer in model.layers]\n",
        "  visualization_model = tf.keras.models.Model(inputs=model.input, outputs=successive_outputs[1:])\n",
        "\n",
        "  idx = randint(0, data.shape[0]-1)\n",
        "  x = np.expand_dims(data[idx], axis=0)\n",
        "\n",
        "  successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "  # let's map the layers of this model with their name\n",
        "  layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "  # plot everything\n",
        "  for layer_name, feature_map in zip(layer_names[1:], successive_feature_maps):\n",
        "    \n",
        "    if len(feature_map.shape) == 4: # if it is a conv or pooling layer\n",
        "      n_features = feature_map.shape[-1]  # n features\n",
        "      size       = feature_map.shape[ 1]  # shape\n",
        "      \n",
        "      # create a grid to display the data\n",
        "      display_grid = np.zeros((size, size * n_features))\n",
        "      \n",
        "      # some post-processing\n",
        "      for i in range(n_features):\n",
        "        x  = feature_map[0, :, :, i]\n",
        "        x -= x.mean()\n",
        "        x /= x.std ()\n",
        "        x *=  64\n",
        "        x += 128\n",
        "        x  = np.clip(x, 0, 255).astype('uint8')\n",
        "        display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "      # show the chart\n",
        "      scale = 20. / n_features\n",
        "      plt.figure( figsize=(scale * n_features, scale) )\n",
        "      plt.title ( layer_name )\n",
        "      plt.grid  ( False )\n",
        "      plt.imshow( display_grid, aspect='auto', cmap='viridis' ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1439e73",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_layer(model, test_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
